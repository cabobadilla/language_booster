import streamlit as st
import openai
import json

# Configuraci贸n inicial
st.set_page_config(page_title="Your Language Booster", layout="centered")

# Encabezado de la aplicaci贸n
st.title("Your Language Booster")
st.markdown(
    """
    隆Bienvenido a Your Language Booster!   
    Selecciona un idioma, nivel y tema para practicar tu comprensi贸n lectora. 
    La aplicaci贸n generar谩 un texto y preguntas para ayudarte a mejorar.
    """
)

# Selecci贸n de par谩metros
idioma = st.selectbox("Selecciona el idioma", ["Ingl茅s", "Italiano"])
nivel = st.selectbox(
    "Selecciona el nivel CEFR",
    [
        "A1 - Principiante 1",
        "A2 - Principiante 2",
        "B1 - Intermedio 1",
        "B2 - Intermedio 2",
        "C1 - Avanzado 1",
        "C2 - Avanzado 2",
    ],
)
tema = st.selectbox("Selecciona el tema", ["Cultura", "Viajes", "Moda", "Historia"])

# Bot贸n para generar texto y preguntas
if st.button("Generar Texto y Preguntas"):
    with st.spinner("Generando contenido..."):
        try:
            # Configuraci贸n de la API
            openai.api_key = st.secrets["openai"]["api_key"]

            # Prompt para generar texto y t铆tulo
            prompt_texto = (
                f"Escribe un texto en {idioma.lower()} con un nivel de dificultad {nivel.split(' ')[0]} "
                f"sobre el tema {tema}. El texto debe tener entre 150 y 200 palabras, ser interesante, "
                "real y con hechos relevantes. Tambi茅n proporciona un t铆tulo breve y relevante para el texto."
            )

            response_texto = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Eres un experto en generar textos educativos."},
                    {"role": "user", "content": prompt_texto},
                ],
                temperature=0.7,
                max_tokens=300,
            )
            texto_generado = response_texto['choices'][0]['message']['content'].strip()

            # Prompt para generar explicaci贸n y preguntas
            prompt_explicacion_y_preguntas = (
                f"Con base en el siguiente texto, escribe una breve explicaci贸n en {idioma.lower()} "
                f"acerca de los principales puntos o temas que el lector deber铆a haber entendido o aprendido "
                f"del texto. Despu茅s de la explicaci贸n, genera 5 preguntas simples en {idioma.lower()} que eval煤en la comprensi贸n, "
                f"incluyendo las respuestas correctas. Devuelve los resultados en formato JSON estructurado "
                f"con las claves: 'explicacion', 'preguntas' (con opciones y respuestas correctas). "
                f"Aseg煤rate de que el JSON est茅 correctamente formateado, sin errores de sintaxis. "
                f"Texto: \"{texto_generado}\""
            )

            response_explicacion_y_preguntas = openai.ChatCompletion.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "Eres un generador de explicaciones y preguntas educativas."},
                    {"role": "user", "content": prompt_explicacion_y_preguntas},
                ],
                temperature=0.7,
                max_tokens=400,
            )

            # Intentar parsear el JSON generado
            try:
                raw_content = response_explicacion_y_preguntas['choices'][0]['message']['content'].strip()

                # Sanitizar contenido JSON
                sanitized_content = raw_content.strip()
                if not sanitized_content.startswith('{') or not sanitized_content.endswith('}'):
                    sanitized_content = sanitized_content[sanitized_content.find('{'):sanitized_content.rfind('}') + 1]

                # Parsear JSON
                resultado = json.loads(sanitized_content)
                explicacion = resultado.get("explicacion", "No se pudo generar una explicaci贸n.")
                preguntas = resultado.get("preguntas", [])
            except (json.JSONDecodeError, ValueError) as e:
                st.error(f"Error al procesar el formato JSON de las preguntas. Detalles: {e}")
                st.text_area("Contenido devuelto por OpenAI (para depuraci贸n):", raw_content)
                st.stop()

            # Mostrar t铆tulo y texto
            st.subheader("T铆tulo del Texto")
            st.write(f" {texto_generado.splitlines()[0]}")  # T铆tulo como primera l铆nea del texto

            st.subheader("Texto Generado")
            st.write("\n".join(texto_generado.splitlines()[1:]))  # El resto es el texto

            st.subheader("Temas Principales")
            st.write(f" {explicacion}")

            # Mostrar preguntas de comprensi贸n
            st.subheader("Preguntas de Comprensi贸n")
            respuestas_correctas = []
            if preguntas:
                for i, pregunta in enumerate(preguntas, 1):
                    st.markdown(f"**{i}. {pregunta['pregunta']}**")
                    respuestas_correctas.append(pregunta.get("correcta", "No disponible"))
            else:
                st.write("No se generaron preguntas. Intenta nuevamente.")

            # Mostrar respuestas correctas en tama帽o peque帽o
            st.subheader("Respuestas Correctas")
            for i, respuesta in enumerate(respuestas_correctas, 1):
                st.markdown(
                    f"<p style='font-size:10px; color:gray'>{i}. {respuesta}</p>",
                    unsafe_allow_html=True,
                )

        except Exception as e:
            st.error(f"Hubo un error al generar el contenido: {e}")
